# Análise de Feedback de Usuários de Agentes de IA: Rumo a Plataformas Ideais e Documentação Aprimorada

Resumo Executivo

Este relatório consolida o feedback de usuários ativos de Agentes de Inteligência Artificial (IA), delineando suas aspirações para plataformas ideais, as funcionalidades cruciais que esperam e os desafios persistentes que enfrentam com as tecnologias atuais de Modelos de Linguagem Grandes (LLMs) e Agentes. A análise deste feedback revela que a demanda latente não é apenas por mais funcionalidades, mas por uma experiência de IA mais coesa, confiável e integrada. Os usuários buscam sistemas que realmente compreendam e antecipem suas necessidades, agindo como verdadeiros "colegas de equipe" digitais.1 Múltiplas fontes indicam um desejo por agentes que vão além de tarefas simples, demonstrando raciocínio e proatividade.2 A frustração com a falta de confiabilidade e a necessidade de supervisão constante 4 sugerem que os usuários almejam um nível de autonomia e confiança que ainda não é comum. Portanto, a coesão, confiabilidade e integração emergem como temas unificadores que transcendem pedidos de funcionalidades específicas; a plataforma ideal não é um amontoado de ferramentas, mas um sistema sinérgico.

Serão destacadas as principais oportunidades de melhoria para o projeto do usuário (a ser nomeado quando sua documentação for fornecida), com foco em alinhar a plataforma com as expectativas da comunidade e mitigar problemas comuns. Finalmente, serão propostas alterações concretas na documentação do projeto para refletir essas melhorias, aumentar a clareza e abordar proativamente as preocupações dos usuários.

---

I. A Visão do Usuário para Plataformas de Agentes de IA: Desejos e Expectativas

A. Construindo a Plataforma Ideal de Agentes de IA: Aspirações Centrais dos Usuários

Os usuários aspiram por plataformas de IA que transcendam a simples execução de tarefas, buscando sistemas que ofereçam insights estratégicos, automação proativa e uma experiência de usuário intuitiva e personalizável. Eles não querem apenas ferramentas, mas parceiros digitais que compreendam seus objetivos. Por exemplo, um agente de análise de e-mail que não apenas identifica problemas, mas sugere correções estratégicas e prevê o impacto, agindo como um "estrategista", exemplifica o desejo por IA que agregue valor analítico e de tomada de decisão.2 A facilidade de interação e uma interface intuitiva são cruciais, com alguns usuários sugerindo a inclusão de um "breve tutorial ou comando de ajuda" para reduzir o atrito na adoção.5

A IA é valorizada por sua capacidade de "reduzir a carga cognitiva" e "sintetizar informações em formatos acionáveis", como auxiliar em consultas complexas ou automatizar trabalhos monótonos.6 Contudo, há uma ressalva contra interfaces de "pergunte-me qualquer coisa" sem orientação adequada, pois podem levar à rotatividade de usuários.6 A ideia de agentes como "colegas de equipe proativos" é reforçada pela expectativa de que eles não apenas identifiquem problemas, mas investiguem o "porquê", proponham próximos passos e até executem experimentos. Isso permitiria que as equipes humanas se concentrassem em estratégias de nível superior.1 Adicionalmente, os agentes de IA são vistos como ferramentas poderosas para transformar a análise de feedback do cliente, automatizando a coleta, analisando grandes volumes de dados e fornecendo insights em tempo real.7 As expectativas se estendem a tarefas complexas, como a geração de conteúdo otimizado para engajamento, como vídeos para TikTok, indicando uma demanda por resultados sofisticados e práticos.8 Com a crescente autonomia dos agentes, surge o conceito de "Agent Experience (AX)", sugerindo que o design das plataformas deve considerar as necessidades dos próprios agentes como usuários para interações autônomas eficazes.9

Observa-se que a plataforma ideal é percebida como um ecossistema adaptativo e colaborativo, e não uma ferramenta monolítica. Os usuários valorizam a capacidade de personalizar agentes 5, integrá-los com seus fluxos de trabalho existentes 2 e até mesmo ter agentes colaborando entre si ou com humanos de forma fluida.1 A personalização de resumos 5, a integração com ferramentas como Google Sheets/Airtable e planos futuros para Mailchimp/Klaviyo 2, e a listagem de "Integração com Sistemas Existentes" e "Suporte Multicanal" como características chave 10 são exemplos dessa necessidade. A capacidade dos agentes de colaborar, debater ideias e aprender uns com os outros 3, ou trabalhar em segundo plano para atingir metas 1, reforça essa visão. A convergência desses pontos sugere que modularidade, interoperabilidade e personalização são fundamentais. Os usuários não querem ser limitados por uma solução única, mas buscam flexibilidade para moldar a IA às suas necessidades e integrá-la profundamente em seus ambientes.

Paralelamente, existe uma tensão perceptível entre o desejo de autonomia poderosa do agente 1 e a necessidade de controle e supervisão do usuário.1 Enquanto os agentes são idealizados como capazes de "tomar decisões independentemente" 3 e executar tarefas complexas autonomamente 1, também é crucial que "Agentes não farão mudanças voltadas para o cliente sem sua aprovação" 1 e que atuem "com a supervisão dos usuários".3 Pilares da IA Responsável, como "Construir Confiança", "Reduzir Danos" e "Promover Responsabilidade" 8, implicam a necessidade de mecanismos de controle e transparência. Esta dualidade sugere que os usuários buscam o poder da automação, mas não à custa da perda de controle ou da introdução de riscos. A plataforma ideal deve, portanto, oferecer níveis configuráveis de autonomia e mecanismos robustos de supervisão e aprovação, os chamados "guardrails".1

B. Funcionalidades Essenciais: O Que os Usuários Exigem dos Agentes de IA

Além de capacidades de conversação e geração, os usuários esperam um conjunto robusto de funcionalidades que incluem raciocínio avançado, planejamento, memória contextual, integração com ferramentas externas (tool use), personalização e análises detalhadas. Um agente de marketing, por exemplo, é esperado que realize varredura de campanhas, identifique baixo desempenho, sugira correções estratégicas baseadas em uma base de conhecimento customizada, preveja resultados e priorize correções, além de permitir a exportação de relatórios via API.2 Para um bot de mensagens, funcionalidades como interface intuitiva, mecanismo de feedback interno, monitoramento da qualidade da resposta com potencial para aprendizado por reforço, personalização de prioridades de informação e escalabilidade são valorizadas.5

Funcionalidades como detecção de anomalias, ferramentas de consulta baseadas em LLM para reduzir carga cognitiva e integração com planilhas são consideradas valiosas, assim como a capacidade de usar técnicas de RAG (Retrieval-Augmented Generation) para alavancar dados existentes.6 O acesso à internet para informações em tempo real, o fornecimento de fontes para evitar alucinações e a integração com ferramentas de produtividade são também destacados.11 As capacidades fundamentais de agentes de IA, como raciocínio, aprendizado, tomada de decisão, processamento multimodal, planejamento, memória (curto prazo, longo prazo, episódica, consenso) e uso de ferramentas, são consideradas essenciais.3

Plataformas de agentes de IA devem oferecer NLU (Natural Language Understanding), aprendizado de máquina para melhoria contínua, integração com sistemas empresariais (CRM, faturamento), escalabilidade, análises e relatórios robustos, intents e entidades personalizáveis, capacidades de agente híbrido (escalonamento para humanos), suporte multicanal, conformidade e segurança, e personalização através de modelos de propensão.10 Agentes especializados por caso de uso (conversão de website, onboarding, adoção de features, monetização) que monitoram métricas, analisam sessões de usuário, implantam guias in-app segmentados e coletam feedback qualitativo são desejáveis, com a adaptabilidade ao ritmo do usuário sendo uma funcionalidade chave.1 A automação da coleta de feedback, análise de grandes datasets, insights em tempo real, análise de sentimento automatizada (NLP), reconhecimento de tendências, respostas personalizadas e integração multicanal com milhares de aplicações também são esperadas.7 Finalmente, o acesso a APIs para integrações e a incorporação de princípios de IA Responsável (transparência, explicabilidade, privacidade, redução de danos, conformidade legal/ética, responsabilidade) são cruciais.8

Uma meta-funcionalidade crítica que emerge da análise é a "capacidade de aprendizado e adaptação contínua".3 Isso transcende o fine-tuning inicial e implica sistemas que melhoram com o uso e feedback. A sugestão de explorar "técnicas como aprendizado por reforço para melhorar o modelo baseado em interações do usuário" 5, a listagem de "aprendizado e auto-aperfeiçoamento" como um benefício 3, e a menção a "aprendizado de máquina para melhorar continuamente as respostas" 10 apontam nessa direção. Técnicas como RLHF (Reinforcement Learning from Human Feedback) e RLAIF (Reinforcement Learning from AI Feedback) são métodos para alinhar LLMs com preferências humanas e melhorar comportamentos 12, e a incorporação de um "Feedback Loop" em sistemas RAG para refinar o recuperador e gerador 13 também são relevantes. Os usuários não veem os agentes como estáticos; eles esperam que a plataforma incorpore mecanismos para que os agentes evoluam, aprendam com os erros e se tornem mais eficazes e alinhados ao longo do tempo.

Outro aspecto fundamental é a "explicabilidade e interpretabilidade" das ações e decisões do agente.2 À medida que os agentes ganham autonomia, os usuários querem entender o "porquê" por trás das sugestões ou ações, não apenas o "o quê". Um agente que "explica o porquê, dá uma correção" 2 é um exemplo disso. A noção de que "Quando a IA é transparente e explicável, as pessoas se sentem mais confortáveis e seguras usando-a" 8 é central. As preocupações com "caixas pretas" 4 e a necessidade de confiar nas saídas dos LLMs 4 reforçam a demanda por mecanismos que permitam aos usuários entender o processo de tomada de decisão do agente. Funcionalidades como logs de decisão auditáveis, visualização de fontes de informação 11, ou a capacidade de questionar o raciocínio do agente seriam altamente valorizadas.

A tabela abaixo consolida as funcionalidades chave desejadas e as expectativas dos usuários:

Tabela 1: Funcionalidades Chave Desejadas para Plataformas de Agentes de IA e Expectativas dos Usuários

  

|   |   |   |   |
|---|---|---|---|
|Categoria da Funcionalidade|Funcionalidades Específicas Desejadas|Expectativa do Usuário/Benefício|Evidência|
|Raciocínio e Decisão|Sugestões estratégicas, Análise preditiva, Planejamento de tarefas, Resolução de problemas complexos|Agregação de valor analítico, Tomada de decisão informada, Proatividade|2|
|Integração e Ferramentas|APIs para sistemas externos (CRM, planilhas, email), Uso de ferramentas (tool use), Acesso à internet em tempo real, Base de conhecimento customizável/RAG|Fluxos de trabalho eficientes e automatizados, Capacidades expandidas, Informação atualizada e aterrada|2|
|Personalização|Customização de intents/entidades, Priorização de informação configurável, Níveis de autonomia ajustáveis, Agentes especializados por caso de uso|Relevância contextual, Adaptação às necessidades específicas do usuário, Controle sobre o comportamento do agente|1|
|Aprendizado e Adaptação|Melhoria contínua baseada em interações e feedback (e.g., RLHF/RLAIF), Memória contextual (curto, longo prazo, episódica)|Agentes que evoluem e se tornam mais eficazes com o tempo, Manutenção de contexto em interações longas|3|
|Transparência e Controle|Fornecimento de fontes/citações, Explicabilidade de decisões (o "porquê"), Logs de auditoria, Mecanismos de supervisão e aprovação, Conformidade e Segurança (GDPR)|Confiança no sistema, Compreensão das ações do agente, Mitigação de riscos, Proteção de dados|2|
|Interface e UX|Interface intuitiva, Facilidade de configuração, Tutoriais e ajuda integrados, Suporte multicanal|Baixo atrito na adoção, Experiência de usuário fluida, Acessibilidade|5|
|Processamento Multimodal|Capacidade de processar e interagir com texto, voz, imagem, vídeo, código|Interações mais ricas e naturais, Capacidade de lidar com diversos tipos de dados|3|
|Análise e Relatórios|Análise de sentimento automatizada, Reconhecimento de tendências, Dashboards de desempenho do agente, Exportação de relatórios|Insights acionáveis a partir de dados, Monitoramento da eficácia, Facilidade de compartilhamento de resultados|2|

---

II. Navegando pelo Labirinto: Desafios Comuns e Frustrações com Agentes de IA & LLMs

A. Pontos Problemáticos Relatados por Usuários com Implementações Atuais de Agentes de IA

As frustrações dos usuários com os agentes de IA atuais frequentemente giram em torno de resultados de baixa qualidade, falta de confiabilidade, dificuldade de configuração e integração, e experiências de usuário abaixo do ideal. Por exemplo, a tentativa de usar o ChatGPT para auditorias de e-mail resultou em feedback de que era "muito genérico e não consistente", levando à necessidade de construir um agente próprio para obter especialização e confiabilidade.2 Uma crítica central é a falta de transparência sobre as limitações dos LLMs, criando uma situação onde "a única maneira de usar LLMs de forma confiável é saber a resposta para a pergunta antes de fazê-la".4 As empresas são criticadas por promoverem LLMs como "ferramentas perfeitas", o que não condiz com a realidade.4

A "inconsistência" é apontada como um grande problema dos LLMs 14, e alguns usuários não confiariam em um LLM para tarefas críticas, como a elaboração de um contrato, se não pudessem verificar o trabalho.14 Relatos de insatisfação incluem a baixa qualidade dos resultados de ferramentas específicas como AnimationDiff no ComfyUI e a dificuldade de configuração.8 Outra queixa comum é que muitas plataformas não oferecem acesso a API ou são excessivamente caras.8 Produtos baseados em agentes podem parecer "extremamente não confiáveis para coisas incrivelmente simples" 9, e há críticas ao "hype" tecnológico que beira a mentira.9 Um problema significativo identificado com o NotebookLM é sua limitação da janela de contexto, que impede o sistema de "ver" todos os dados carregados, resultando em informações incorretas e minando a confiança do usuário, que se sente enganado pela promessa de análise completa de dados.15 LLMs também demonstram falhas em tarefas que exigem raciocínio estruturado real, como a criação de uma máquina de Turing simples, expondo suas fraquezas além do casamento de padrões e podendo errar em tarefas como contagem de caracteres, regex, quebra-cabeças lógicos e provas matemáticas.16

Uma desconexão significativa existe entre o hype e as promessas de marketing em torno dos Agentes de IA e a realidade da experiência do usuário.4 Essa disparidade leva à desilusão e desconfiança.15 A "bolha de hype dos LLMs" é frequentemente construída com base em "potencial futuro nebuloso" e "promessas enganosas dos provedores de LLM".4 A percepção de que "Precisamos parar de promover tanto a tecnologia. É quase mentira" 9 e a constatação de que as pessoas temem a IA porque não entendem suas limitações reais são sintomas dessa desconexão. Quando um usuário descobre uma limitação não comunicada claramente, como no caso da janela de contexto do NotebookLM, a reação é de desconfiança: "como posso confiar nisso?".15 Isso sugere que as plataformas precisam ser mais transparentes sobre as capacidades e limitações atuais, e a documentação desempenha um papel crucial nesse aspecto, não apenas para explicar como usar a ferramenta, mas também para gerenciar expectativas de forma realista.

Ademais, a "complexidade de configuração e a falta de padronização ou interoperabilidade" entre diferentes ferramentas e agentes de IA são barreiras significativas para a adoção e satisfação do usuário.8 Queixas como "muitos programas não têm acesso a API ou são realmente caros" e a dificuldade de "configurar tudo" 8 são comuns. A complexidade de decidir entre fluxos de trabalho agente-para-agente versus agente-para-ferramenta indica que "desenvolvedores não deveriam ter que fazer essas escolhas difíceis".17 A percepção de que "é necessário muito andaime para construir e executar agentes" 18 sugere que o processo ainda não é simples ou intuitivo. Isso implica que plataformas que simplificam a criação, configuração e orquestração de agentes, e que promovem a interoperabilidade (por exemplo, através de APIs abertas ou aderência a padrões), terão uma vantagem competitiva. A documentação deve guiar os usuários claramente através dessas complexidades.

B. Limitações Fundamentais e Preocupações com a Tecnologia LLM

As limitações inerentes aos LLMs, como alucinações, vieses, problemas de janela de contexto, altos custos computacionais, e a dificuldade em garantir privacidade e segurança, são fontes contínuas de preocupação e desafios técnicos. LLMs podem alucinar, com alguns modelos admitindo a possibilidade de terem inventado informações.4 A natureza fundamental dos LLMs pode, por si só, causar incoerência.4 Um LLM não censurado reconhece suas próprias limitações, como dificuldade em entender contexto e emoções, falta de empatia e originalidade, potencial para respostas enganosas, enviesadas ou tóxicas, preocupações com a privacidade dos dados de treinamento e alto consumo de energia. A consistência é citada como um grande problema.14

Insuficiências de design em agentes LLM incluem questões de privacidade (dados sensíveis em entradas multimodais, compartilhamento com ferramentas externas, gerenciamento de memória), viés (amplificação de padrões prejudiciais, vieses herdados de ferramentas), sustentabilidade (altas demandas computacionais), eficácia (problemas de integração, alucinação intermodal, dependência de ferramentas, gerenciamento de memória ineficiente) e transparência (processos de decisão opacos).19 Armadilhas na integração de LLM abrangem preparação de dados insuficiente (datasets enviesados minam a eficácia), ignorar necessidades de escalabilidade (custos de token podem disparar), não lidar com viés no modelo e ignorar preocupações com privacidade e segurança, como a conformidade com GDPR e o EU AI Act.20

A limitação da janela de contexto é um problema fundamental, onde o LLM não processa toda a informação fornecida, levando a erros.15 LLMs também lutam com raciocínio estruturado e tarefas que exigem correção formal, pois são essencialmente preditores de tokens, não "mentes pensantes".16 O Supervised Fine-Tuning (SFT) pode levar a comportamentos não intencionais, como a invenção de fatos (alucinações) ou conteúdo enviesado/tóxico. Técnicas como RLHF/RLAIF são usadas para alinhar LLMs para serem mais honestos e inofensivos, mas medir honestidade é difícil, e LLMs frequentemente alucinam por falta de mecanismos para reconhecer as limitações de seu conhecimento.12

Desafios técnicos na construção de agentes de IA incluem o gerenciamento da integração de ferramentas (que introduz pontos de falha e considerações de segurança), o gerenciamento do raciocínio e da tomada de decisão do modelo (devido à sua natureza não determinística) e a manipulação de processos de múltiplos passos e contexto (que exige gerenciamento de estado e tratamento de erros robustos).21 A integração de LLMs com sistemas legados apresenta desafios como arquiteturas incompatíveis, limites de hardware, problemas de dados (formatos desatualizados, baixa qualidade) e preocupações com segurança e privacidade.22 A alucinação de LLM, definida como a geração de respostas factualmente incorretas, mas convincentes, é uma grande ameaça à confiabilidade, e sua medição é complexa.23 Alguns estudos argumentam que é impossível eliminar completamente a alucinação em LLMs, pois eles não podem aprender todas as funções computáveis e, portanto, inevitavelmente alucinarão se usados como solucionadores de problemas gerais.24 Janelas de contexto maiores, embora permitam o processamento de documentos mais longos, trazem desvantagens como custos aumentados (devido a mais tokens de entrada) e latência de token de saída aumentada, pois prompts mais longos geralmente levam a uma geração de saída mais lenta.25

A "questão da alucinação" 4 não é apenas um defeito a ser corrigido, mas uma característica potencialmente inerente à tecnologia LLM atual.24 Isso tem implicações profundas para a confiabilidade e os casos de uso viáveis. Múltiplas fontes identificam a alucinação como um problema central.4 Um estudo formal sugere que a eliminação completa da alucinação pode ser impossível.24 Diante disso, plataformas de agentes devem focar em mitigação e gerenciamento de alucinações. Estratégias como RAG robusto, citação de fontes 11, e mecanismos de verificação são cruciais. A plataforma Phind, por exemplo, fornece fontes para suas afirmações, ajudando a evitar alucinações e permitindo verificação.11 O RLHF é usado para tornar LLMs mais "honestos" 12, e o feedback do usuário pode melhorar sistemas RAG 13, que são uma estratégia chave para aterrar LLMs em fatos. Em vez de buscar uma "cura" para a alucinação, o foco prático para plataformas de agentes deve ser em construir sistemas resilientes que minimizem sua ocorrência, forneçam transparência sobre a proveniência da informação e permitam aos usuários verificar e corrigir as saídas. A documentação deve ser honesta sobre esse desafio.

Existe também um trade-off fundamental entre a sofisticação/capacidade do agente e os custos/complexidade/desempenho.20 Janelas de contexto maiores aumentam os custos de token e a latência de saída.25 Ignorar necessidades de escalabilidade pode levar a custos de token inesperadamente altos.20 Cada ferramenta adicional introduz potenciais pontos de falha e implicações de desempenho 21, e há altos custos computacionais e de energia associados a LLMs e seus componentes.19 Isso indica que não existe uma solução "tamanho único". Os usuários precisarão de orientação para equilibrar a necessidade de capacidades avançadas com as realidades de custo, desempenho e complexidade de gerenciamento. A plataforma pode precisar oferecer diferentes "níveis" de agentes ou modelos, e a documentação deve explicar claramente os prós e contras de cada um.

A tabela a seguir resume os problemas comuns e frustrações com LLMs e Agentes de IA:

Tabela 2: Problemas Comuns e Frustrações com LLMs/Agentes de IA

  

|   |   |   |   |
|---|---|---|---|
|Categoria do Problema|Problemas Específicos Relatados|Impacto nos Usuários|Evidência|
|Confiabilidade e Precisão|Alucinações, Inconsistência, Respostas genéricas/superficiais, Falha em raciocínio estruturado, Incapacidade de reconhecer limitações de conhecimento|Desconfiança, Necessidade de verificação manual constante, Resultados incorretos, Tomada de decisão prejudicada|4|
|Usabilidade e Configuração|Dificuldade de configuração, Interfaces pouco intuitivas, Falta de APIs ou integrações complexas, Curva de aprendizado íngreme para ferramentas avançadas|Frustração, Adoção lenta, Tempo perdido em configuração em vez de uso produtivo, Dependência de especialistas|5|
|Limitações do Modelo|Janela de contexto limitada (não processa toda a informação), Vieses herdados dos dados de treinamento, Dificuldade em entender nuances, emoções e contexto profundo|Análises incompletas ou incorretas, Resultados discriminatórios ou injustos, Falha em tarefas complexas, Interações superficiais|14|
|Custo e Desempenho|Custo elevado de tokens (especialmente com janelas de contexto grandes), Alto consumo de energia/recursos computacionais, Latência na geração de respostas|Custos inesperados e proibitivos, Preocupações ambientais, Experiência de usuário lenta|14|
|Privacidade e Segurança|Risco de exposição de dados sensíveis (no treinamento ou uso), Conformidade com regulações (GDPR, etc.), Vulnerabilidade a ataques adversariais|Violações de privacidade, Perda de dados confidenciais, Riscos legais e reputacionais, Manipulação do agente|10|
|Transparência e Hype|Falta de transparência sobre limitações reais dos LLMs, Promessas de marketing exageradas (hype vs. realidade), Opacidade dos processos de decisão ("caixa preta")|Desilusão, Desconfiança na tecnologia, Dificuldade em avaliar a adequação da ferramenta para uma tarefa específica|4|

---

III. Preenchendo a Lacuna: Oportunidades para Aprimorar o Projeto [Nome do Projeto do Usuário]

(Esta seção dependerá da análise da documentação específica do projeto do usuário, que não foi fornecida. O conteúdo abaixo serve como um modelo metodológico e exemplificativo de como a análise seria conduzida.)

A. Alinhando o Projeto [Nome do Projeto do Usuário] com as Expectativas dos Usuários

Para alinhar o Projeto [Nome do Projeto do Usuário] com as expectativas identificadas, uma análise comparativa será realizada entre suas funcionalidades e filosofia (conforme sua documentação) e as aspirações e funcionalidades desejadas detalhadas nas Seções I.A e I.B deste relatório.

Metodologia Proposta:

1. Revisão da Documentação do Projeto: Análise detalhada da documentação do Projeto [Nome do Projeto do Usuário] para compreender suas capacidades atuais, arquitetura, casos de uso primários, público-alvo e roadmap (se disponível).
    
2. Mapeamento de Funcionalidades: Comparação das funcionalidades existentes do projeto com as listadas na Tabela 1: Funcionalidades Chave Desejadas para Plataformas de Agentes de IA e Expectativas dos Usuários.
    
3. Identificação de Lacunas e Pontos Fortes: Identificar áreas onde o projeto não atende (ou atende parcialmente) às expectativas dos usuários, bem como pontos onde ele já se alinha ou excede essas expectativas.
    

Exemplo de Análise (Hipotético):

Suponha que a documentação do "Projeto Alfa" indique um forte foco na automação de tarefas repetitivas através de prompts de linguagem natural simples. Embora isso se alinhe com o desejo do usuário por "redução de carga cognitiva" 6, pode não abordar completamente a aspiração por "insights estratégicos" e "sugestões de correção" 2 que usuários mais avançados buscam. Uma oportunidade clara para o "Projeto Alfa" seria expandir suas capacidades analíticas, talvez permitindo a integração de uma base de conhecimento customizável, similar ao agente de análise de e-mail descrito 2, ou incorporando módulos de planejamento e previsão.

Com base na documentação do projeto, pode-se perceber que o projeto está focado em um subconjunto específico de personas de usuário, potencialmente negligenciando as necessidades de usuários mais técnicos ou estratégicos que buscam maior personalização, controle granular e capacidades de integração via API. Se a documentação do projeto enfatizar a simplicidade e casos de uso básicos, enquanto o feedback da comunidade (Seção I) demonstra uma forte demanda por APIs abertas, personalização avançada e controle detalhado, existirá uma desconexão evidente. Isso sugere que o projeto pode precisar desenvolver uma "camada avançada" de funcionalidades ou ajustar seu roadmap para contemplar esses recursos, a fim de reter e atrair usuários experientes que valorizam flexibilidade e poder.

Tabela Proposta (Condicional à Documentação do Projeto): Tabela 3: Análise de Lacunas: Projeto [Nome do Projeto do Usuário] vs. Expectativas dos Usuários.

|   |   |   |   |
|---|---|---|---|
|Funcionalidade/Expectativa Desejada (da Tabela 1)|Status Atual no Projeto [Nome do Projeto do Usuário] (Conforme Documentação)|Análise da Lacuna/Oportunidade|Recomendação Estratégica para o Projeto|
|Ex: Sugestões estratégicas e previsão de impacto|Ex: Focado em execução de tarefas; sem análise preditiva explícita.|Ex: Lacuna na entrega de valor estratégico. Oportunidade de diferenciar-se ao oferecer mais do que simples automação.|Ex: Desenvolver/integrar módulo de análise e previsão. Permitir conexão com bases de conhecimento para recomendações baseadas em dados.|
|Ex: Acesso programático via API robusta|Ex: API limitada ou inexistente.|Ex: Dificulta a integração em fluxos de trabalho existentes e o desenvolvimento de soluções customizadas por usuários técnicos.|Ex: Priorizar o desenvolvimento de uma API completa e bem documentada, seguindo padrões abertos para facilitar a adoção por desenvolvedores.|
|Ex: Mecanismos de aprendizado e adaptação|Ex: Modelo estático; sem feedback loop claro.|Ex: Perde a oportunidade de melhorar com o tempo e se alinhar melhor às preferências do usuário.|Ex: Implementar um sistema de coleta de feedback (explícito e implícito) e explorar RLHF/RLAIF para refinar o comportamento do agente ao longo do tempo.|

B. Abordando Desafios Comuns de IA no Projeto [Nome do Projeto do Usuário]

Esta subseção avaliará como o Projeto [Nome do Projeto do Usuário] atualmente lida (ou planeja lidar) com os desafios e limitações comuns de Agentes de IA e LLMs identificados na Seção II.

Metodologia Proposta:

1. Análise da Documentação: Revisão da documentação do projeto em busca de menções a estratégias de mitigação para problemas como alucinações, vieses, gerenciamento de contexto, segurança, privacidade, desempenho e custos.
    
2. Comparação com Melhores Práticas: Confrontar as abordagens do projeto (se existirem) com as melhores práticas ou soluções emergentes discutidas (e.g., uso de RAG, RLHF, transparência de fontes, explicabilidade, gerenciamento de janela de contexto).
    
3. Identificação de Vulnerabilidades: Apontar áreas onde o projeto pode ser vulnerável aos problemas comuns ou onde suas estratégias de mitigação podem ser insuficientes ou não claramente comunicadas.
    

Exemplo de Análise (Hipotético):

Se a documentação do "Projeto Beta" mencionar o uso de um LLM de última geração, mas não detalhar mecanismos específicos para lidar com alucinações além de prompting padrão, isso representa uma área de atenção. Dado que a alucinação é uma preocupação central para os usuários 4 e que a capacidade de verificar fontes é valorizada 11, uma oportunidade significativa para o "Projeto Beta" seria implementar ou, se já existente, destacar uma arquitetura RAG robusta.13 Isso ajudaria a aterrar as respostas do agente em dados verificáveis e, crucialmente, documentar essa abordagem de forma transparente para construir a confiança do usuário.

Pode-se também inferir, a partir da documentação, se o projeto está subestimando o impacto da "Agent Experience (AX)" 9, especialmente se seus agentes são projetados para interagir com outros sistemas ou serem integrados por terceiros. Se a documentação do projeto focar exclusivamente na experiência do usuário final e não abordar como outros agentes ou desenvolvedores podem interagir com seus agentes de forma programática (via APIs claras, formatos de dados padronizados, protocolos de comunicação bem definidos), ele pode enfrentar desafios de adoção em ecossistemas de IA mais amplos. A consideração da AX sugere que a documentação para desenvolvedores e as capacidades de integração são tão importantes quanto a interface do usuário final, pois a colaboração eficaz entre agentes e a facilidade de integração são cada vez mais esperadas.

---

IV. Evoluindo a Narrativa: Recomendações para a Documentação do Projeto [Nome do Projeto do Usuário]

(Esta seção também dependerá da análise da documentação específica do projeto do usuário. As recomendações serão adaptadas ao documento fornecido.)

A. Aprimorando a Clareza e a Orientação ao Usuário na Documentação Atual

Com base na análise da documentação existente e no feedback geral sobre a necessidade de clareza (evidenciada pela preferência por interfaces intuitivas 5 e a aversão a sistemas que exigem adivinhação por parte do usuário 6), propõem-se melhorias na estrutura, linguagem e exemplos da documentação.

Recomendações Potenciais Gerais:

- Linguagem Clara e Concisa: Adotar uma linguagem acessível, evitando jargão técnico excessivo. Quando termos técnicos forem indispensáveis, devem ser claramente definidos em um glossário ou na primeira ocorrência.
    
- Guias "Getting Started" e Tutoriais Detalhados: Desenvolver guias de início rápido e tutoriais passo a passo para facilitar o onboarding de novos usuários e a compreensão de funcionalidades chave.5
    
- Casos de Uso e Exemplos Práticos Relevantes: Ilustrar o valor do agente com exemplos concretos de cenários de uso reais, demonstrando como ele pode resolver problemas específicos ou atingir objetivos definidos.1
    
- Seção de Troubleshooting/FAQ Abrangente e Proativa: Antecipar e abordar problemas comuns, erros frequentes e perguntas frequentes, fornecendo soluções claras e diretas.
    
- Melhorar a Navegabilidade e Estrutura da Informação: Organizar a documentação de forma lógica e intuitiva, com um índice claro, pesquisa eficiente e links cruzados para garantir que os usuários encontrem facilmente a informação que necessitam.
    

Exemplo de Recomendação (Hipotético):

Se a seção "Configuração Avançada" da documentação do "Projeto Gama" for identificada como densa e pressupondo um alto nível de conhecimento prévio, recomenda-se reestruturá-la. Poderia ser dividida em subseções menores e mais focadas, cada uma com exemplos de código passo a passo, capturas de tela (se aplicável) e explicações claras para cada parâmetro de configuração. Esta abordagem reflete a necessidade de clareza expressa pelos usuários ao enfrentarem configurações complexas.8

É fundamental reconhecer que a documentação não é apenas um manual de referência, mas uma ferramenta crucial para gerenciar as expectativas do usuário em relação às capacidades e limitações da IA.4 A falta de transparência sobre as limitações dos LLMs é um grande problema 4, e a frustração do usuário ao descobrir uma limitação não comunicada claramente é palpável.15 Se a documentação apenas exaltar as capacidades sem discutir honestamente os limites (por exemplo, sobre alucinações, precisão da janela de contexto, possíveis vieses), ela contribui para a desconexão entre o hype e a realidade. Portanto, uma seção dedicada a "Limitações Conhecidas e Melhores Práticas para Mitigação" pode construir confiança e ajudar os usuários a obterem melhores resultados, mesmo que isso signifique admitir que a ferramenta não é "perfeita".

B. Incorporando Novas Funcionalidades e Melhores Práticas à Documentação

Sugere-se como documentar novas funcionalidades que podem ser adicionadas ao Projeto [Nome do Projeto do Usuário] com base nas descobertas da Seção III.A, ou como destacar melhor as funcionalidades existentes que ressoam com os desejos dos usuários.

Recomendações Potenciais Gerais:

- Documentar claramente como o projeto permite personalização, incluindo exemplos de como adaptar o agente para diferentes tarefas ou preferências do usuário.5
    
- Explicar em detalhes as capacidades de integração e APIs, fornecendo guias para desenvolvedores e exemplos de código.2
    
- Detalhar quaisquer mecanismos de aprendizado contínuo ou feedback implementados, explicando como os usuários podem contribuir para a melhoria do agente.5
    
- Se o projeto utilizar RAG, explicar a arquitetura de forma acessível, como os usuários podem otimizar a base de conhecimento para melhores resultados e as limitações dessa abordagem.13
    
- Se houver funcionalidades alinhadas com "IA Responsável" (transparência, explicabilidade, controle de viés), destacá-las e explicar seu funcionamento e benefícios.8
    

Exemplo de Recomendação (Hipotético):

Se o "Projeto Alfa" implementar a capacidade de exportar análises para Google Sheets (conforme o desejo identificado em 2), a documentação deve incluir um tutorial passo a passo sobre como configurar a integração da API, autenticação e um exemplo de template de planilha. Deve-se demonstrar o valor prático dessa integração com um caso de uso, como o monitoramento de métricas de campanha de marketing.

A documentação pode também servir como um canal para educar os usuários sobre como 'pensar' com agentes de IA e como formular prompts ou delegar tarefas de forma eficaz, especialmente para funcionalidades mais complexas ou não determinísticas.16 Os LLMs podem falhar em tarefas de raciocínio puramente estruturado 16, e gerenciar o raciocínio não determinístico dos modelos é um desafio.21 Os usuários podem não entender intuitivamente como delegar tarefas a um agente de IA ou como interpretar seus resultados, e interfaces excessivamente abertas sem orientação podem ser problemáticas.6 A documentação pode ir além de descrever botões e APIs, oferecendo seções como "Melhores práticas para interagir com seu agente", "Dicas de engenharia de prompt para o Projeto [Nome do Projeto do Usuário]", ou "Como decompor tarefas complexas para o agente". Isso não apenas melhora a eficácia do usuário, mas também aumenta a satisfação geral com a plataforma.

C. Abordando Proativamente Possíveis Preocupações dos Usuários na Documentação

Recomenda-se a inclusão de seções na documentação que abordem diretamente as preocupações e limitações identificadas na Seção II.B.

Recomendações Potenciais Gerais:

- Declaração de Privacidade e Segurança de Dados: Detalhar como os dados do usuário são coletados, tratados, armazenados, anonimizados (se aplicável) e protegidos, e como o sistema adere a regulações como GDPR.10
    
- Gerenciamento de Vieses: Explicar quaisquer esforços para identificar e mitigar vieses nos modelos e nos dados, e como os usuários podem estar cientes e reportar possíveis vieses.19
    
- Lidando com Alucinações/Imprecisões: Reconhecer abertamente a possibilidade de o LLM gerar informações incorretas. Fornecer dicas sobre como os usuários podem verificar informações, a importância de usar fontes externas para dados críticos e orientar sobre os tipos de tarefas onde a precisão absoluta é menos crítica versus aquelas que exigem supervisão humana rigorosa.4
    
- Limitações da Janela de Contexto: Se aplicável ao modelo utilizado, explicar de forma clara como a janela de contexto funciona, qual seu tamanho, e como os usuários podem otimizar entradas longas para garantir que a informação mais relevante seja processada.15
    
- Uso Ético e Responsável: Fornecer diretrizes claras sobre o uso apropriado da plataforma, desencorajando usos maliciosos ou antiéticos, e alinhando-se com os princípios de IA Responsável.8
    

Exemplo de Recomendação (Hipotético):

Incluir uma seção na documentação do "Projeto Beta" intitulada "Entendendo e Gerenciando as Respostas do Agente". Esta seção deve explicar brevemente por que LLMs podem, por vezes, gerar informações factualmente incorretas (referenciando a natureza da tecnologia, como em 14), como o "Projeto Beta" tenta minimizar isso (e.g., através de RAG, prompting específico, ou fornecendo fontes quando possível), e aconselhar os usuários a sempre cruzar informações críticas, especialmente para casos de uso sensíveis ou de alto impacto.

A documentação proativa sobre limitações e riscos não apenas gerencia expectativas, mas também pode capacitar os usuários a se tornarem parceiros na melhoria da plataforma. Por exemplo, ao entenderem as possíveis falhas, eles podem fornecer feedback mais informado ou sinalizar comportamentos problemáticos do agente de forma mais construtiva.5 Se os usuários sabem que o agente pode alucinar e encontram um exemplo, podem reportá-lo de maneira direcionada, contribuindo para os ciclos de RLHF/RLAIF. Isso transforma a documentação de uma comunicação unidirecional em um facilitador de um ciclo de feedback bidirecional, alinhando-se com o desejo de aprendizado e adaptação contínua da plataforma.

Tabela Proposta (Condicional à Documentação do Projeto): Tabela 4: Melhorias Propostas para a Documentação do Projeto [Nome do Projeto do Usuário].

  

|   |   |   |   |
|---|---|---|---|
|Área/Seção da Documentação (Atual ou Nova)|Problema/Oportunidade Identificado (Baseado no Feedback da Comunidade e Análise do Projeto)|Mudança/Adição Sugerida à Documentação|Justificativa/Benefício Esperado|
|Ex: Guia de Início Rápido|Ex: Usuários novos podem ter dificuldade em entender os primeiros passos e o valor imediato.|Ex: Criar um tutorial visual e interativo, focado em um caso de uso simples, mas de alto impacto, mostrando resultados em poucos minutos.|Ex: Reduzir o tempo de onboarding, aumentar a taxa de ativação de novos usuários, demonstrar rapidamente o ROI da plataforma.|
|Ex: Nova Seção: "Privacidade e Segurança dos Seus Dados"|Ex: Usuários expressam preocupações sobre como seus dados são usados por LLMs e Agentes de IA.14|Ex: Detalhar políticas de retenção de dados, medidas de anonimização, criptografia, conformidade com GDPR/LGPD, e como os dados são usados para treinar/melhorar o agente (se aplicável).|Ex: Construir confiança, abordar proativamente preocupações de privacidade, garantir conformidade legal e demonstrar um compromisso com a segurança dos dados do usuário.|
|Ex: Documentação de API|Ex: Desenvolvedores precisam de mais exemplos e clareza sobre endpoints e autenticação para integrar o agente em seus sistemas.8|Ex: Adicionar exemplos de código em múltiplas linguagens populares, um "playground" de API interativo, e guias detalhados para casos de uso comuns de integração.|Ex: Facilitar a integração por terceiros, expandir o ecossistema em torno do projeto, aumentar a adoção por usuários técnicos que necessitam de customização e automação avançada.|
|Ex: Seção: "Entendendo as Limitações e Maximizando a Precisão"|Ex: Usuários frustrados com alucinações e falta de transparência sobre as capacidades reais do LLM.4|Ex: Explicar o conceito de alucinação, as estratégias de mitigação do projeto (e.g., RAG), e fornecer dicas para verificar informações e usar o agente de forma eficaz.|Ex: Gerenciar expectativas realisticamente, reduzir a frustração do usuário, capacitar os usuários a obterem melhores resultados e a usarem a ferramenta de forma mais consciente e segura.|

---

Conclusão

A análise do feedback de usuários de Agentes de IA revela um panorama claro de desejos e desafios. Os usuários anseiam por plataformas que sejam mais do que meros executores de tarefas; eles buscam parceiros digitais estratégicos, adaptáveis e equipados com funcionalidades robustas de raciocínio, planejamento, memória contextual, integração transparente com outras ferramentas e amplas capacidades de personalização. A capacidade de um agente aprender e se adaptar continuamente, juntamente com a transparência em suas operações, são vistas como cruciais para construir uma relação de confiança.

Paralelamente, desafios persistentes como a falta de confiabilidade, a ocorrência de alucinações, dificuldades de usabilidade e configuração, e uma frequente desconexão entre as promessas da tecnologia e sua performance real, continuam a ser fontes significativas de frustração. As limitações inerentes aos LLMs, incluindo a gestão da janela de contexto, vieses e as preocupações com privacidade e segurança, exigem abordagens proativas e transparentes por parte dos desenvolvedores de plataformas.

Para o Projeto [Nome do Projeto do Usuário], as oportunidades residem em alinhar suas funcionalidades e filosofia com essas expectativas elevadas, ao mesmo tempo em que mitiga ativamente os problemas comuns identificados. Isso pode envolver o aprimoramento de capacidades analíticas, o fortalecimento de mecanismos de integração e personalização, e a implementação de sistemas que promovam a confiabilidade e a explicabilidade.

Neste contexto, a documentação emerge não apenas como um manual de instruções, mas como um pilar fundamental na construção da confiança do usuário e na facilitação de uma experiência de IA bem-sucedida. Uma documentação clara, honesta, abrangente e proativa pode gerenciar expectativas, educar os usuários sobre as nuances da interação com Agentes de IA, e abordar de frente suas preocupações. O sucesso futuro das plataformas de Agentes de IA dependerá intrinsecamente da capacidade de construir uma relação de parceria transparente e confiável com os usuários. Nesta relação, a IA deve ser percebida como uma extensão capacitadora das habilidades humanas, e a documentação serve como a ponte essencial para essa compreensão e colaboração eficaz.

#### Referências citadas

1. Introducing Amplitude AI Agents, acessado em junho 12, 2025, [https://amplitude.com/blog/ai-agents](https://amplitude.com/blog/ai-agents)
    
2. Reddit helped us improve our AI email analyst - here's what's ..., acessado em junho 12, 2025, [https://www.reddit.com/r/AI_Agents/comments/1l6dkzj/reddit_helped_us_improve_our_ai_email_analyst/](https://www.reddit.com/r/AI_Agents/comments/1l6dkzj/reddit_helped_us_improve_our_ai_email_analyst/)
    
3. What are AI agents? Definition, examples, and types | Google Cloud, acessado em junho 12, 2025, [https://cloud.google.com/discover/what-are-ai-agents](https://cloud.google.com/discover/what-are-ai-agents)
    
4. The lack of transparency on LLM limitations is going to lead to ..., acessado em junho 12, 2025, [https://www.reddit.com/r/singularity/comments/1j7xwgt/the_lack_of_transparency_on_llm_limitations_is/](https://www.reddit.com/r/singularity/comments/1j7xwgt/the_lack_of_transparency_on_llm_limitations_is/)
    
5. I launched my first AI agent. Looking for feedback. : r/AI_Agents, acessado em junho 12, 2025, [https://www.reddit.com/r/AI_Agents/comments/1l8cyen/i_launched_my_first_ai_agent_looking_for_feedback/](https://www.reddit.com/r/AI_Agents/comments/1l8cyen/i_launched_my_first_ai_agent_looking_for_feedback/)
    
6. What AI features have actually impressed you? : r ... - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/ProductManagement/comments/1j9q3ry/what_ai_features_have_actually_impressed_you/](https://www.reddit.com/r/ProductManagement/comments/1j9q3ry/what_ai_features_have_actually_impressed_you/)
    
7. Transforming Customer Feedback Analysis with AI Agents, acessado em junho 12, 2025, [https://aiagent.app/usecases/ai-agents-for-customer-feedback-analysis](https://aiagent.app/usecases/ai-agents-for-customer-feedback-analysis)
    
8. AI Agents - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/AI_Agents/rising/](https://www.reddit.com/r/AI_Agents/rising/)
    
9. Designing for the Agent Experience (AX) and its effect on UX : r/UXDesign - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/UXDesign/comments/1idsdjw/designing_for_the_agent_experience_ax_and_its/](https://www.reddit.com/r/UXDesign/comments/1idsdjw/designing_for_the_agent_experience_ax_and_its/)
    
10. What Are the Key Features of an AI Agent Platform? - Webio, acessado em junho 12, 2025, [https://www.webio.com/faq/what-are-the-key-features-of-an-ai-agent-platform](https://www.webio.com/faq/what-are-the-key-features-of-an-ai-agent-platform)
    
11. Best AI Platforms - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/klp/best-ai-platforms/](https://www.reddit.com/klp/best-ai-platforms/)
    
12. Fine-tune large language models with reinforcement learning from human or AI feedback, acessado em junho 12, 2025, [https://aws.amazon.com/blogs/machine-learning/fine-tune-large-language-models-with-reinforcement-learning-from-human-or-ai-feedback/](https://aws.amazon.com/blogs/machine-learning/fine-tune-large-language-models-with-reinforcement-learning-from-human-or-ai-feedback/)
    
13. Retrieval-Augmented Generation (RAG) Explained: Key Questions Answered - Ralabs, acessado em junho 12, 2025, [https://ralabs.org/blog/overcoming-challenges-in-payments-and-transactions-2/](https://ralabs.org/blog/overcoming-challenges-in-payments-and-transactions-2/)
    
14. The Brutal Truth about LLMs : r/ArtificialInteligence - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/](https://www.reddit.com/r/ArtificialInteligence/comments/1ivvkc0/the_brutal_truth_about_llms/)
    
15. I now understand Notebook LLM's limitations - and you should too : r ..., acessado em junho 12, 2025, [https://www.reddit.com/r/notebooklm/comments/1l2aosy/i_now_understand_notebook_llms_limitations_and/](https://www.reddit.com/r/notebooklm/comments/1l2aosy/i_now_understand_notebook_llms_limitations_and/)
    
16. What are the current limits of LLMs? : r/ChatGPT - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/ChatGPT/comments/1kj9q07/what_are_the_current_limits_of_llms/](https://www.reddit.com/r/ChatGPT/comments/1kj9q07/what_are_the_current_limits_of_llms/)
    
17. Agent-to-Agent vs Agent-to-Tool — How are you designing your agent workflows? - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/AI_Agents/comments/1jygsy3/agenttoagent_vs_agenttotool_how_are_you_designing/](https://www.reddit.com/r/AI_Agents/comments/1jygsy3/agenttoagent_vs_agenttotool_how_are_you_designing/)
    
18. Useful AI agents or workflow automations for product managers? - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/ProductManagement/comments/1iw0zip/useful_ai_agents_or_workflow_automations_for/](https://www.reddit.com/r/ProductManagement/comments/1iw0zip/useful_ai_agents_or_workflow_automations_for/)
    
19. LLM Agents: How They Work and Where They Go Wrong - Holistic AI, acessado em junho 12, 2025, [https://www.holisticai.com/blog/llm-agents-use-cases-risks](https://www.holisticai.com/blog/llm-agents-use-cases-risks)
    
20. 12 common pitfalls in LLM agent integration (and how to avoid them), acessado em junho 12, 2025, [https://www.barrage.net/blog/technology/12-pitfalls-in-llm-integration-and-how-to-avoid-them](https://www.barrage.net/blog/technology/12-pitfalls-in-llm-integration-and-how-to-avoid-them)
    
21. Building AI agents: 5 common hurdles and fixes - Cohere, acessado em junho 12, 2025, [https://cohere.com/blog/building-ai-agents](https://cohere.com/blog/building-ai-agents)
    
22. Integrating LLMs with Legacy Systems: Challenges | newline - Fullstack.io, acessado em junho 12, 2025, [https://www.newline.co/@zaoyang/integrating-llms-with-legacy-systems-challenges--f305ef96](https://www.newline.co/@zaoyang/integrating-llms-with-legacy-systems-challenges--f305ef96)
    
23. measuring and reducing llm hallucination - arXiv, acessado em junho 12, 2025, [https://arxiv.org/pdf/2402.10412](https://arxiv.org/pdf/2402.10412)
    
24. Hallucination is Inevitable: An Innate Limitation of Large Language Models - arXiv, acessado em junho 12, 2025, [https://arxiv.org/abs/2401.11817](https://arxiv.org/abs/2401.11817)
    
25. Understanding the Impact of Increasing LLM Context Windows - Meibel, acessado em junho 12, 2025, [https://www.meibel.ai/post/understanding-the-impact-of-increasing-llm-context-windows](https://www.meibel.ai/post/understanding-the-impact-of-increasing-llm-context-windows)
    
26. How can we incorporate user feedback or real user queries into building a dataset for RAG evaluation, and what are the challenges with using real-world queries? - Milvus, acessado em junho 12, 2025, [https://milvus.io/ai-quick-reference/how-can-we-incorporate-user-feedback-or-real-user-queries-into-building-a-dataset-for-rag-evaluation-and-what-are-the-challenges-with-using-realworld-queries](https://milvus.io/ai-quick-reference/how-can-we-incorporate-user-feedback-or-real-user-queries-into-building-a-dataset-for-rag-evaluation-and-what-are-the-challenges-with-using-realworld-queries)
    
27. RAG systems is only as good as the LLM you choose to use. - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/Rag/comments/1krztg5/rag_systems_is_only_as_good_as_the_llm_you_choose/](https://www.reddit.com/r/Rag/comments/1krztg5/rag_systems_is_only_as_good_as_the_llm_you_choose/)
    
28. RAG - Usable for my application? : r/LocalLLaMA - Reddit, acessado em junho 12, 2025, [https://www.reddit.com/r/LocalLLaMA/comments/1l7d9gf/rag_usable_for_my_application/](https://www.reddit.com/r/LocalLLaMA/comments/1l7d9gf/rag_usable_for_my_application/)
    

**